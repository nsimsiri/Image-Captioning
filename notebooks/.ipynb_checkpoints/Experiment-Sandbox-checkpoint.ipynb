{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "src_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.image_processor import default_image_transform\n",
    "from src.config import CaptionConfig\n",
    "from src.data_loader import CaptionDataManager\n",
    "from src.image_processor import train_transform\n",
    "from src.base_experiment import plot_eval\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "data = defaultdict(dict)\n",
    "\n",
    "Y_test = [x**2 for x in range(20)]\n",
    "Y_train = [math.sqrt(x) for x in range(20)]\n",
    "Y_val = [x for x in range(20)]\n",
    "\n",
    "data['loss']['train'] = Y_train\n",
    "data['loss']['test'] = Y_test\n",
    "data['loss']['val'] = Y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_eval(data, 'train', name='loss')\n",
    "# plot_eval(data, 'test', name='loss')\n",
    "# plot_eval(data, 'val', name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nsimsiri/Documents/code/ml/nlp/cap/src/config.yml\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2747.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "loaded - val captions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loaded {} samples 100\n",
      "<src.data_loader.CaptionDataManager object at 0x1a205f54e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_path = os.path.join(src_path, \"src\",\"config.yml\") \n",
    "print(config_path)\n",
    "assert(os.path.exists(config_path))\n",
    "\n",
    "manager = CaptionDataManager(config_path, n_sample=100)\n",
    "\n",
    "print(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPER-PARAM[vocab=425 embed=32 hidden=64 num_layers=1 ]\n",
      "total param #: 131945\n",
      "decoder param #: 66313\n"
     ]
    }
   ],
   "source": [
    "from src.models.base_model import EncoderDecoder\n",
    "\n",
    "vocab_size      = len(manager.vocab())\n",
    "embed_size      = 32\n",
    "hidden_size     = 64\n",
    "num_layers      = 1\n",
    "\n",
    "num_epochs      = 30\n",
    "learning_rate   = 0.001\n",
    "\n",
    "\n",
    "print(\"HYPER-PARAM[vocab={} embed={} hidden={} num_layers={} ]\".format(vocab_size, \n",
    "                                                                       embed_size, \n",
    "                                                                       hidden_size,\n",
    "                                                                       num_layers))\n",
    "net = EncoderDecoder(vocab_size, \n",
    "                     embed_size=embed_size, \n",
    "                     hidden_size=hidden_size,\n",
    "                     num_layers=num_layers)\n",
    "\n",
    "total_param_count = sum(param.numel() for param in net.parameters())\n",
    "decoder_param_count = sum(param.numel() for param in net.decoder.parameters())\n",
    "print(\"total param #: \" + str(total_param_count))\n",
    "print(\"decoder param #: \" + str(decoder_param_count))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=0 step=2 loss=4.958033323287964\n",
      "ep=0 step=4 loss=4.855225324630737\n",
      "ep=0 step=6 loss=4.818835496902466\n",
      "ep=0 step=8 loss=4.815541326999664\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'no data of key-type = loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e6630d5aee83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mall_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogged_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mplot_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_loss_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t time elasped for epoch: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/ml/nlp/cap/src/base_experiment.py\u001b[0m in \u001b[0;36mplot_eval\u001b[0;34m(data, split_type, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no data of key-type = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'no data of key-type = loss'"
     ]
    }
   ],
   "source": [
    "from src.image_processor import train_transform, default_image_transform\n",
    "from src.base_experiment import plot_eval, run_model\n",
    "import time \n",
    "train_loader = manager.build_dataloader('train', \n",
    "                                        batch_size=10, \n",
    "                                        shuffle=True, \n",
    "#                                         image_transform=train_transform)\n",
    "                                        image_transform=default_image_transform)\n",
    "# val_loader   = manager.build_dataloader('val', \n",
    "#                                         batch_size=5)\n",
    "# test_loader  = manager.build_dataloader('test', \n",
    "#                                         batch_size=5)\n",
    "\n",
    "all_losses = []\n",
    "plot_loss_map = {\n",
    "    'loss': {'train': all_losses}\n",
    "}\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    losses, logged_losses = run_model(net, \n",
    "                          train_loader, \n",
    "                          criterion, \n",
    "                          optimizer,\n",
    "                          train=True,\n",
    "                          epoch=epoch)\n",
    "\n",
    "    all_losses += logged_losses\n",
    "    plot_eval(plot_loss_map, \"train\", name='loss')\n",
    "    print(\"\\t time elasped for epoch: {}\".format(time.time()-t0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.base_experiment import evaluate_model\n",
    "evaluate_model(net, train_loader, criterion, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, _ = run_model(net, \n",
    "                      train_loader, \n",
    "                      criterion, \n",
    "                      optimizer,\n",
    "                      train=True,\n",
    "                      epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
