{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "src_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.image_processor import default_image_transform\n",
    "from src.config import CaptionConfig\n",
    "from src.data_loader import CaptionDataManager\n",
    "from src.image_processor import train_transform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(src_path, \"src\",\"config.yml\") \n",
    "print(config_path)\n",
    "assert(os.path.exists(config_path))\n",
    "\n",
    "manager = CaptionDataManager(config_path)\n",
    "print(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "train_loader = manager.build_dataloader('train', \n",
    "                                        batch_size=5, \n",
    "                                        shuffle=True, \n",
    "                                        image_transform=train_transform)\n",
    "print(train_loader)\n",
    "for x in train_loader:\n",
    "    annIds, imgs, caps, caplens = x\n",
    "    print(annIds.shape)\n",
    "    print(imgs.shape)\n",
    "    print(caps.shape)\n",
    "    print(caps)\n",
    "    print(caplens.shape)\n",
    "    print()\n",
    "#     for i in range(5):\n",
    "#         annId, img, cap, caplen = annIds[i], imgs[i], caps[i], caplens[i]\n",
    "#         cap = torch.Tensor(cap)\n",
    "#         print(cap)\n",
    "#         print(manager.decode_tokens(cap.numpy().tolist(), length=caplen))\n",
    "#         img_np = np.swapaxes(img.numpy(), 2, 0)\n",
    "#         plt.imshow(img_np)\n",
    "#         plt.show()\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# batch_size = 3\n",
    "# max_length = 3\n",
    "# hidden_size = 2\n",
    "# n_layers =1\n",
    "\n",
    "# # container\n",
    "# batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "# #data\n",
    "# # vec_1 = torch.FloatTensor([[1, 2, 3]])\n",
    "# # vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "# # vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "# # batch_in[0] = vec_1\n",
    "# # batch_in[1] = vec_2\n",
    "# # batch_in[2] = vec_3\n",
    "\n",
    "# batch_in = torch.FloatTensor([[1,2,3],[1,2,0],[1,0,0]])\n",
    "# print(batch_in.shape)\n",
    "\n",
    "# # batch_in = Variable(batch_in)\n",
    "# batch_in = batch_in.unsqueeze(2)\n",
    "# print(batch_in.shape)\n",
    "\n",
    "# seq_lengths = [3,2, # list of integers holding information about the batch size at each sequence step\n",
    "\n",
    "# # pack it\n",
    "# pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "# print(pack.data.shape)\n",
    "\n",
    "# # # initialize\n",
    "# max_length = 1\n",
    "# rnn = nn.RNN(max_length, hidden_size, n_layers, batch_first=True) \n",
    "# h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "# print(pack)\n",
    "# # #forward \n",
    "# rnn(pack, h0)\n",
    "\n",
    "# # # unpack\n",
    "# # unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import LongTensor\n",
    "# from torch.nn import Embedding, LSTM\n",
    "# from torch.autograd import Variable\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# ## We want to run LSTM on a batch of 3 character sequences ['long_str', 'tiny', 'medium']\n",
    "# #\n",
    "# #     Step 1: Construct Vocabulary\n",
    "# #     Step 2: Load indexed data (list of instances, where each instance is list of character indices)\n",
    "# #     Step 3: Make Model\n",
    "# #  *  Step 4: Pad instances with 0s till max length sequence\n",
    "# #  *  Step 5: Sort instances by sequence length in descending order\n",
    "# #  *  Step 6: Embed the instances\n",
    "# #  *  Step 7: Call pack_padded_sequence with embeded instances and sequence lengths\n",
    "# #  *  Step 8: Forward with LSTM\n",
    "# #  *  Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector\n",
    "# #  *  Summary of Shape Transformations\n",
    "\n",
    "# # We want to run LSTM on a batch following 3 character sequences\n",
    "# seqs = ['long_str',  # len = 8\n",
    "#         'tiny',      # len = 4\n",
    "#         'medium']    # len = 6\n",
    "\n",
    "\n",
    "# ## Step 1: Construct Vocabulary ##\n",
    "# ##------------------------------##\n",
    "# # make sure <pad> idx is 0\n",
    "# vocab = ['<pad>'] + sorted(set([char for seq in seqs for char in seq]))\n",
    "# # => ['<pad>', '_', 'd', 'e', 'g', 'i', 'l', 'm', 'n', 'o', 'r', 's', 't', 'u', 'y']\n",
    "\n",
    "\n",
    "# ## Step 2: Load indexed data (list of instances, where each instance is list of character indices) ##\n",
    "# ##-------------------------------------------------------------------------------------------------##\n",
    "# vectorized_seqs = [[vocab.index(tok) for tok in seq]for seq in seqs]\n",
    "# # vectorized_seqs => [[6, 9, 8, 4, 1, 11, 12, 10],\n",
    "# #                     [12, 5, 8, 14],\n",
    "# #                     [7, 3, 2, 5, 13, 7]]\n",
    "\n",
    "\n",
    "# ## Step 3: Make Model ##\n",
    "# ##--------------------##\n",
    "# embed = Embedding(len(vocab), 4) # embedding_dim = 4\n",
    "# lstm = LSTM(input_size=4, hidden_size=5, batch_first=True) # input_dim = 4, hidden_dim = 5\n",
    "\n",
    "\n",
    "# ## Step 4: Pad instances with 0s till max length sequence ##\n",
    "# ##--------------------------------------------------------##\n",
    "\n",
    "# # get the length of each seq in your batch\n",
    "# seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
    "# # seq_lengths => [ 8, 4,  6]\n",
    "# # batch_sum_seq_len: 8 + 4 + 6 = 18\n",
    "# # max_seq_len: 8\n",
    "\n",
    "# seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "# # seq_tensor => [[0 0 0 0 0 0 0 0]\n",
    "# #                [0 0 0 0 0 0 0 0]\n",
    "# #                [0 0 0 0 0 0 0 0]]\n",
    "\n",
    "# for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "#     seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
    "# # seq_tensor => [[ 6  9  8  4  1 11 12 10]          # long_str\n",
    "# #                [12  5  8 14  0  0  0  0]          # tiny\n",
    "# #                [ 7  3  2  5 13  7  0  0]]         # medium\n",
    "# # seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)\n",
    "\n",
    "\n",
    "# ## Step 5: Sort instances by sequence length in descending order ##\n",
    "# ##---------------------------------------------------------------##\n",
    "\n",
    "# seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "# seq_tensor = seq_tensor[perm_idx]\n",
    "# # seq_tensor => [[ 6  9  8  4  1 11 12 10]           # long_str\n",
    "# #                [ 7  3  2  5 13  7  0  0]           # medium\n",
    "# #                [12  5  8 14  0  0  0  0]]          # tiny\n",
    "# # seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)\n",
    "\n",
    "\n",
    "# ## Step 6: Embed the instances ##\n",
    "# ##-----------------------------##\n",
    "\n",
    "# embedded_seq_tensor = embed(seq_tensor)\n",
    "# # embedded_seq_tensor =>\n",
    "# #                       [[[-0.77578706 -1.8080667  -1.1168439   1.1059115 ]     l\n",
    "# #                         [-0.23622951  2.0361056   0.15435742 -0.04513785]     o\n",
    "# #                         [-0.6000342   1.1732816   0.19938554 -1.5976517 ]     n\n",
    "# #                         [ 0.40524676  0.98665565 -0.08621677 -1.1728264 ]     g\n",
    "# #                         [-1.6334635  -0.6100042   1.7509955  -1.931793  ]     _\n",
    "# #                         [-0.6470658  -0.6266589  -1.7463604   1.2675372 ]     s\n",
    "# #                         [ 0.64004815  0.45813003  0.3476034  -0.03451729]     t\n",
    "# #                         [-0.22739866 -0.45782727 -0.6643252   0.25129375]]    r\n",
    "\n",
    "# #                        [[ 0.16031227 -0.08209462 -0.16297023  0.48121014]     m\n",
    "# #                         [-0.7303265  -0.857339    0.58913064 -1.1068314 ]     e\n",
    "# #                         [ 0.48159844 -1.4886451   0.92639893  0.76906884]     d\n",
    "# #                         [ 0.27616557 -1.224429   -1.342848   -0.7495876 ]     i\n",
    "# #                         [ 0.01795524 -0.59048957 -0.53800726 -0.6611691 ]     u\n",
    "# #                         [ 0.16031227 -0.08209462 -0.16297023  0.48121014]     m\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]     <pad>\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]]    <pad>\n",
    "\n",
    "# #                        [[ 0.64004815  0.45813003  0.3476034  -0.03451729]     t\n",
    "# #                         [ 0.27616557 -1.224429   -1.342848   -0.7495876 ]     i\n",
    "# #                         [-0.6000342   1.1732816   0.19938554 -1.5976517 ]     n\n",
    "# #                         [-1.284392    0.68294704  1.4064184  -0.42879772]     y\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]     <pad>\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]     <pad>\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]     <pad>\n",
    "# #                         [ 0.2691206  -0.43435425  0.87935454 -2.2269666 ]]]   <pad>\n",
    "# # embedded_seq_tensor.shape : (batch_size X max_seq_len X embedding_dim) = (3 X 8 X 4)\n",
    "\n",
    "\n",
    "# ## Step 7: Call pack_padded_sequence with embeded instances and sequence lengths ##\n",
    "# ##-------------------------------------------------------------------------------##\n",
    "\n",
    "# packed_input = pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
    "# # packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
    "# #\n",
    "# # packed_input.data =>\n",
    "# #                         [[-0.77578706 -1.8080667  -1.1168439   1.1059115 ]     l\n",
    "# #                          [ 0.01795524 -0.59048957 -0.53800726 -0.6611691 ]     m\n",
    "# #                          [-0.6470658  -0.6266589  -1.7463604   1.2675372 ]     t\n",
    "# #                          [ 0.16031227 -0.08209462 -0.16297023  0.48121014]     o\n",
    "# #                          [ 0.40524676  0.98665565 -0.08621677 -1.1728264 ]     e\n",
    "# #                          [-1.284392    0.68294704  1.4064184  -0.42879772]     i\n",
    "# #                          [ 0.64004815  0.45813003  0.3476034  -0.03451729]     n\n",
    "# #                          [ 0.27616557 -1.224429   -1.342848   -0.7495876 ]     d\n",
    "# #                          [ 0.64004815  0.45813003  0.3476034  -0.03451729]     n\n",
    "# #                          [-0.23622951  2.0361056   0.15435742 -0.04513785]     g\n",
    "# #                          [ 0.16031227 -0.08209462 -0.16297023  0.48121014]     i\n",
    "# #                          [-0.22739866 -0.45782727 -0.6643252   0.25129375]]    y\n",
    "# #                          [-0.7303265  -0.857339    0.58913064 -1.1068314 ]     _\n",
    "# #                          [-1.6334635  -0.6100042   1.7509955  -1.931793  ]     u\n",
    "# #                          [ 0.27616557 -1.224429   -1.342848   -0.7495876 ]     s\n",
    "# #                          [-0.6000342   1.1732816   0.19938554 -1.5976517 ]     m\n",
    "# #                          [-0.6000342   1.1732816   0.19938554 -1.5976517 ]     t\n",
    "# #                          [ 0.48159844 -1.4886451   0.92639893  0.76906884]     r\n",
    "# # packed_input.data.shape : (batch_sum_seq_len X embedding_dim) = (18 X 4)\n",
    "# #\n",
    "# # packed_input.batch_sizes => [ 3,  3,  3,  3,  2,  2,  1,  1]\n",
    "# # visualization :\n",
    "# # l  o  n  g  _  s  t  r   #(long_str)\n",
    "# # m  e  d  i  u  m         #(medium)\n",
    "# # t  i  n  y               #(tiny)\n",
    "# # 3  3  3  3  2  2  1  1   (sum = 18 [batch_sum_seq_len])\n",
    "\n",
    "\n",
    "# ## Step 8: Forward with LSTM ##\n",
    "# ##---------------------------##\n",
    "\n",
    "# packed_output, (ht, ct) = lstm(packed_input)\n",
    "# # packed_output (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
    "# #\n",
    "# # packed_output.data :\n",
    "# #                          [[-0.00947162  0.07743231  0.20343193  0.29611713  0.07992904]   l\n",
    "# #                           [ 0.08596145  0.09205993  0.20892891  0.21788561  0.00624391]   o\n",
    "# #                           [ 0.16861682  0.07807446  0.18812777 -0.01148055 -0.01091915]   n\n",
    "# #                           [ 0.20994528  0.17932937  0.17748171  0.05025435  0.15717036]   g\n",
    "# #                           [ 0.01364102  0.11060348  0.14704391  0.24145307  0.12879576]   _\n",
    "# #                           [ 0.02610307  0.00965587  0.31438383  0.246354    0.08276576]   s\n",
    "# #                           [ 0.09527554  0.14521319  0.1923058  -0.05925677  0.18633027]   t\n",
    "# #                           [ 0.09872741  0.13324396  0.19446367  0.4307988  -0.05149471]   r\n",
    "# #                           [ 0.03895474  0.08449443  0.18839942  0.02205326  0.23149511]   m\n",
    "# #                           [ 0.14620507  0.07822411  0.2849248  -0.22616537  0.15480657]   e\n",
    "# #                           [ 0.00884941  0.05762182  0.30557525  0.373712    0.08834908]   d\n",
    "# #                           [ 0.12460691  0.21189159  0.04823487  0.06384943  0.28563985]   i\n",
    "# #                           [ 0.01368293  0.15872964  0.03759198 -0.13403234  0.23890573]   u\n",
    "# #                           [ 0.00377969  0.05943518  0.2961751   0.35107893  0.15148178]   m\n",
    "# #                           [ 0.00737647  0.17101538  0.28344846  0.18878219  0.20339936]   t\n",
    "# #                           [ 0.0864429   0.11173367  0.3158251   0.37537992  0.11876849]   i\n",
    "# #                           [ 0.17885767  0.12713005  0.28287745  0.05562563  0.10871304]   n\n",
    "# #                           [ 0.09486895  0.12772645  0.34048414  0.25930756  0.12044918]]  y\n",
    "# # packed_output.data.shape : (batch_sum_seq_len X hidden_dim) = (18 X 5)\n",
    "\n",
    "# # packed_output.batch_sizes => [ 3,  3,  3,  3,  2,  2,  1,  1] (same as packed_input.batch_sizes)\n",
    "# # visualization :\n",
    "# # l  o  n  g  _  s  t  r   #(long_str)\n",
    "# # m  e  d  i  u  m         #(medium)\n",
    "# # t  i  n  y               #(tiny)\n",
    "# # 3  3  3  3  2  2  1  1   (sum = 18 [batch_sum_seq_len])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
