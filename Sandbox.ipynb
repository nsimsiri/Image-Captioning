{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.],\n",
      "        [ 2.,  3.]])\n",
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 5])\n",
      "3\n",
      "<class 'torch.nn.modules.activation.Softmax'>\n",
      "tensor([[[ 4.2484e-18,  4.2484e-18,  4.2484e-18,  4.2484e-18,  4.2484e-18]],\n",
      "\n",
      "        [[ 2.0612e-09,  2.0612e-09,  2.0612e-09,  2.0612e-09,  2.0612e-09]],\n",
      "\n",
      "        [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsimsiri/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((3,5,2,2))\n",
    "b = torch.arange(3*5*2*2).view((3,5,2,2))\n",
    "print b[0,0]\n",
    "c = b.view((3,5,4));\n",
    "d = c.permute(0,2,1)\n",
    "# print c\n",
    "print d.shape\n",
    "a = torch.mean(d, 1)\n",
    "print a.shape\n",
    "f = a.unsqueeze(1);\n",
    "(n,_,_) = f.shape\n",
    "print n\n",
    "# print d.contiguous().view((12, 5)).shape\n",
    "\n",
    "print nn.Softmax\n",
    "softmax = nn.Softmax()\n",
    "print softmax(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0.,   1.,   2.,   3.],\n",
      "         [  4.,   5.,   6.,   7.],\n",
      "         [  8.,   9.,  10.,  11.]],\n",
      "\n",
      "        [[ 12.,  13.,  14.,  15.],\n",
      "         [ 16.,  17.,  18.,  19.],\n",
      "         [ 20.,  21.,  22.,  23.]]])\n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.]])\n",
      "tensor([[[ 1.],\n",
      "         [ 1.],\n",
      "         [ 1.]],\n",
      "\n",
      "        [[ 2.],\n",
      "         [ 2.],\n",
      "         [ 2.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(2*3*4).view((2,3,4))\n",
    "b = torch.Tensor(([[1,1,1],[2,2,2]]));\n",
    "\n",
    "print a\n",
    "print b\n",
    "print b.unsqueeze(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'ensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-17aa6a774447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'ensor'"
     ]
    }
   ],
   "source": [
    "a = torch.ensor([[1,10,5],[3,4,6]])\n",
    "k = torch.max(a, 1)\n",
    "print k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print torch.LongTensor\n",
    "a = [[2]*5]\n",
    "print a\n",
    "print torch.LongTensor(a).permute(1,0)\n",
    "a.append([3]*5)\n",
    "print torch.LongTensor(a).permute(1,0).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,0],[0,1]]);\n",
    "a == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-54656b93d46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "nn.Linear((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  0.],\n",
      "        [ 2.,  0.,  0.]])\n",
      "tensor([ 1.,  2.,  2.])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "a = torch.Tensor([1,2,0])\n",
    "b = torch.Tensor([2,0,0])\n",
    "# print a;\n",
    "# print b;\n",
    "c = [a, b]\n",
    "d = torch.cat(c)\n",
    "d= d.view(2,3)\n",
    "# print d\n",
    "# pad = nn.ConstantPad2d((0, 3, 0, 0), 0)\n",
    "# pad(d)\n",
    "\n",
    "\n",
    "print d\n",
    "p = pack_padded_sequence(d, [2,1], batch_first=True)\n",
    "print p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [4 x 5], m2: [10 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524587833086/work/aten/src/TH/generic/THTensorMath.c:2033",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8d6788317f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nsimsiri/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nsimsiri/anaconda2/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nsimsiri/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [4 x 5], m2: [10 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524587833086/work/aten/src/TH/generic/THTensorMath.c:2033"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(10,5)\n",
    "lin(torch.ones((2,2,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0937, -0.4152, -0.3878, -0.0381,  0.0701,  0.2543,  0.0421,\n",
      "         -0.2882,  0.2461,  0.0185, -0.1538, -0.0595,  0.4648, -0.4311,\n",
      "          0.4542, -0.5407, -0.1600, -0.2503,  0.3507,  0.1312],\n",
      "        [-0.2614,  0.2839,  0.0587,  0.2826,  0.2533, -0.2470, -0.2364,\n",
      "          0.0000, -0.0872, -0.0372,  0.0163, -0.0026, -0.1796,  0.2320,\n",
      "          0.0879, -0.0894,  0.1247,  0.1188,  0.2327, -0.4107],\n",
      "        [ 0.1628,  0.1558,  0.0810, -0.0965, -0.1226,  0.0772,  0.1181,\n",
      "          0.0451,  0.1111,  0.0025,  0.6456,  0.0857, -0.3449, -0.0136,\n",
      "         -0.4903, -0.3808, -0.5094, -0.6081,  0.3369, -0.0570]])\n",
      "tensor([[-0.1468, -0.2558, -0.0722,  0.0437,  0.0083,  0.3352, -0.0410,\n",
      "         -0.2019,  0.1008, -0.0994, -0.2410, -0.1242,  0.2235, -0.0717,\n",
      "          0.4086, -0.1755, -0.0915, -0.3064,  0.1193,  0.0406],\n",
      "        [-0.1289,  0.2011,  0.0329,  0.0762,  0.3608,  0.0329, -0.3407,\n",
      "         -0.0280, -0.1587,  0.0105,  0.0979,  0.0483, -0.1269,  0.0795,\n",
      "         -0.0097, -0.2400,  0.2308,  0.1525,  0.4549, -0.2135],\n",
      "        [ 0.0410,  0.1259,  0.0353, -0.0237, -0.1480, -0.0819,  0.1191,\n",
      "          0.0601,  0.0516,  0.1603,  0.1922, -0.0669, -0.1337,  0.0510,\n",
      "         -0.4403, -0.3408, -0.2178, -0.2076,  0.1168,  0.0588]])\n",
      "tensor([[ 0.0015, -0.1721, -0.2597,  0.1613, -0.0266,  0.1743, -0.0138,\n",
      "          0.0183, -0.0511, -0.1030, -0.2784, -0.0944,  0.0954, -0.0726,\n",
      "          0.1737, -0.1360, -0.0694, -0.0969,  0.1416, -0.0533],\n",
      "        [-0.0463,  0.1365, -0.0117, -0.0034,  0.1734,  0.0701, -0.4086,\n",
      "          0.0290, -0.1739,  0.0308,  0.0510,  0.0725, -0.2015,  0.0525,\n",
      "          0.0688, -0.1759,  0.2273, -0.0139,  0.0581, -0.0189],\n",
      "        [-0.0701,  0.0677, -0.0077,  0.0139, -0.1658, -0.0911,  0.0757,\n",
      "         -0.1231,  0.0723, -0.0008, -0.0398, -0.1194, -0.0744,  0.1311,\n",
      "         -0.0265, -0.1049, -0.0876, -0.2223,  0.0213, -0.0223]])\n",
      "tensor([[-0.1357, -0.0474, -0.1063,  0.1168, -0.0322,  0.2378, -0.0023,\n",
      "         -0.1104, -0.0382,  0.0113, -0.1994, -0.0208, -0.0688, -0.1929,\n",
      "          0.0796,  0.0909, -0.0650, -0.1417,  0.0080, -0.1343],\n",
      "        [-0.0407,  0.0294,  0.0200,  0.0548, -0.0113,  0.0214, -0.2029,\n",
      "          0.1435, -0.2044, -0.1283,  0.0604,  0.0308, -0.0618,  0.0168,\n",
      "          0.0965, -0.1649,  0.0285,  0.0071, -0.0146, -0.0629],\n",
      "        [-0.0715,  0.0932, -0.1070,  0.0524, -0.1091, -0.0147, -0.0876,\n",
      "         -0.0346, -0.1258,  0.1823, -0.0933,  0.0717, -0.0590,  0.0173,\n",
      "         -0.1855, -0.0504, -0.0593, -0.1543, -0.1427,  0.0858]])\n",
      "tensor([[-0.0893, -0.0800, -0.0491,  0.2657, -0.0802,  0.1312,  0.1580,\n",
      "          0.0543, -0.1128, -0.0456, -0.2201, -0.1490,  0.0368, -0.1666,\n",
      "         -0.0858, -0.1136, -0.0887, -0.0367,  0.1152, -0.1280],\n",
      "        [ 0.0313,  0.0505,  0.1663,  0.0601, -0.0100,  0.1027,  0.0308,\n",
      "          0.1468, -0.2391, -0.1162, -0.0928, -0.1087, -0.1151, -0.0083,\n",
      "          0.0544, -0.1853, -0.0028, -0.0224,  0.0572, -0.0034],\n",
      "        [-0.1367,  0.1835, -0.0485, -0.0250, -0.1217, -0.0546, -0.0836,\n",
      "          0.0310, -0.1445,  0.1677,  0.0709,  0.1146, -0.1229, -0.0361,\n",
      "         -0.1290, -0.0563, -0.0640, -0.1379, -0.1507, -0.0343]])\n",
      "tensor([[-0.2544, -0.2533,  0.0678,  0.1695, -0.1310,  0.2736,  0.0399,\n",
      "         -0.1754, -0.0128, -0.1408, -0.2263, -0.2578, -0.0493, -0.0712,\n",
      "          0.1326,  0.0185, -0.0536, -0.1390, -0.0193, -0.1183],\n",
      "        [-0.0441,  0.0397,  0.1445,  0.0546, -0.1241,  0.0667, -0.0066,\n",
      "          0.1408, -0.2480, -0.1220,  0.0303, -0.0627, -0.0701,  0.0162,\n",
      "         -0.0848, -0.2036, -0.0595, -0.0306, -0.0509,  0.0098],\n",
      "        [-0.1022,  0.0968,  0.1125, -0.0366, -0.2355,  0.1325,  0.0256,\n",
      "         -0.0248, -0.0815,  0.1218,  0.0621,  0.1362, -0.1407,  0.0515,\n",
      "         -0.1427, -0.0595,  0.0055, -0.0651, -0.0670, -0.0164]])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTMCell(10, 20)\n",
    "input = torch.randn(6, 3, 10)\n",
    "hx = torch.randn(3, 20)\n",
    "cx = torch.randn(3, 20)\n",
    "output = []\n",
    "for i in range(6):\n",
    "    hx, cx = rnn(input[i], (hx, cx))\n",
    "    print hx\n",
    "    output.append(hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0008, -0.2089,  0.0966, -0.1651,  0.2627,  0.0346, -0.0783,\n",
      "         -0.0905, -0.0033, -0.0517, -0.0245, -0.2322, -0.2592,  0.2088,\n",
      "          0.0805,  0.4692, -0.0764, -0.0229, -0.2737,  0.1096],\n",
      "        [-0.0031,  0.1830,  0.0601, -0.3145,  0.0753, -0.0486, -0.0985,\n",
      "         -0.2938, -0.3305, -0.1643,  0.0111, -0.3854,  0.2234,  0.1723,\n",
      "          0.0439,  0.0240,  0.1799,  0.0841, -0.3588,  0.2864],\n",
      "        [ 0.4569, -0.3563, -0.0972, -0.6499,  0.4495, -0.5737, -0.1641,\n",
      "         -0.3186,  0.2924, -0.1375,  0.1283, -0.6805,  0.0052,  0.1608,\n",
      "          0.6188,  0.0614,  0.1541,  0.0447, -0.1431,  0.2494]]), tensor([[ 0.0098, -0.2167,  0.1034,  0.0078,  0.1166, -0.1862, -0.0687,\n",
      "         -0.1902, -0.1562,  0.0212, -0.0588, -0.1849, -0.0533,  0.1473,\n",
      "         -0.0486,  0.4164,  0.0630, -0.0878, -0.1822,  0.1624],\n",
      "        [-0.2480,  0.0883,  0.4933, -0.1493,  0.0419, -0.0008, -0.0425,\n",
      "         -0.0309, -0.1494, -0.0466, -0.2064, -0.4090,  0.0157,  0.3085,\n",
      "          0.1768,  0.1006, -0.0970,  0.0506, -0.0644,  0.3227],\n",
      "        [ 0.2143, -0.0761, -0.0880, -0.4133,  0.2678, -0.3098, -0.2049,\n",
      "         -0.2328,  0.0722, -0.0269,  0.2221, -0.3213,  0.2471,  0.0057,\n",
      "          0.2465, -0.0000, -0.0490,  0.0152,  0.0182,  0.0778]]), tensor([[-0.0291, -0.1256,  0.2023, -0.0767,  0.1289, -0.1548, -0.0091,\n",
      "         -0.0929, -0.0847, -0.0044,  0.0361, -0.2459, -0.0797,  0.1619,\n",
      "         -0.0246,  0.3634,  0.0936, -0.1292,  0.0061,  0.1106],\n",
      "        [-0.0421, -0.0736,  0.1211, -0.1073, -0.0356,  0.0367, -0.0345,\n",
      "          0.0134, -0.4175,  0.0134,  0.0775, -0.3098,  0.1072,  0.0729,\n",
      "         -0.0354,  0.1194,  0.1222, -0.0093, -0.0826,  0.1692],\n",
      "        [ 0.0460, -0.0668, -0.0863, -0.4885,  0.2159, -0.3404, -0.0602,\n",
      "         -0.1427,  0.0118,  0.0135,  0.2297, -0.3686,  0.2476, -0.0415,\n",
      "         -0.0035,  0.1761, -0.0918, -0.1167,  0.1188, -0.0083]]), tensor([[ 0.0926, -0.1598, -0.0076, -0.0821, -0.0338, -0.1857,  0.0635,\n",
      "         -0.1790, -0.1423,  0.0621,  0.1328, -0.0841,  0.0224, -0.0592,\n",
      "         -0.0878,  0.3229,  0.1088, -0.0977, -0.0992, -0.0582],\n",
      "        [-0.0494,  0.0395,  0.0977, -0.0709, -0.0378, -0.1215, -0.2129,\n",
      "         -0.0780, -0.2688,  0.0583,  0.1511, -0.2653,  0.0336, -0.0952,\n",
      "         -0.0554,  0.0081, -0.0016, -0.0760, -0.0710,  0.1101],\n",
      "        [ 0.0576, -0.0625,  0.0473, -0.3702,  0.2041, -0.1384, -0.3493,\n",
      "         -0.0780,  0.0036,  0.0711, -0.0279, -0.0644,  0.0346, -0.1486,\n",
      "         -0.0104,  0.1370, -0.1071, -0.0564,  0.2454,  0.1396]]), tensor([[ 0.1636,  0.1156,  0.1266, -0.0470, -0.0207, -0.2240, -0.3559,\n",
      "         -0.0438, -0.1137,  0.0820,  0.2061, -0.1516,  0.0014, -0.1182,\n",
      "         -0.2434,  0.0603, -0.0286, -0.1503, -0.0072,  0.0064],\n",
      "        [-0.0984,  0.1444,  0.1673, -0.1400, -0.1684,  0.0019, -0.1568,\n",
      "          0.0067, -0.1537,  0.0707,  0.1445, -0.0428, -0.0898, -0.2235,\n",
      "          0.1561,  0.0200, -0.1070, -0.0846,  0.0105,  0.0506],\n",
      "        [-0.1259, -0.0310,  0.0629, -0.3074,  0.1529, -0.2157, -0.1650,\n",
      "          0.0143,  0.0992,  0.1621,  0.1225, -0.2690,  0.0634,  0.0256,\n",
      "         -0.0967,  0.0533, -0.1390, -0.1427,  0.1744,  0.0466]]), tensor([[ 0.1351, -0.1270,  0.0695,  0.0395, -0.1536, -0.1432, -0.0788,\n",
      "         -0.0500, -0.4629,  0.1289,  0.3159, -0.2227,  0.0412, -0.1324,\n",
      "         -0.1306,  0.0163,  0.1767, -0.1402, -0.1734, -0.0490],\n",
      "        [-0.1247, -0.0539,  0.1856, -0.1442, -0.0824,  0.0637, -0.1987,\n",
      "         -0.0724, -0.2150,  0.0379,  0.0911, -0.1243, -0.0924, -0.1753,\n",
      "          0.1557, -0.0446, -0.0818, -0.1207,  0.1337,  0.1101],\n",
      "        [ 0.0567, -0.0513,  0.1500, -0.1933,  0.0337, -0.2342, -0.3174,\n",
      "          0.0515, -0.0708,  0.1941,  0.1949, -0.2137,  0.1001,  0.0322,\n",
      "         -0.2458,  0.0970, -0.1473, -0.0856,  0.1248,  0.0704]])]\n"
     ]
    }
   ],
   "source": [
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.]]), tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.]])]\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.]])\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(2*3).view((2,3))\n",
    "b = torch.arange(2*3).view((2,3))\n",
    "print [a,b] # 2,2,3\n",
    "c = torch.cat([a,b])\n",
    "print c\n",
    "print c.view((2,2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
